{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3427 - loss: 1.7822\n",
      "Epoch 2/5\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5253 - loss: 1.2805\n",
      "Epoch 3/5\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5727 - loss: 1.1603\n",
      "Epoch 4/5\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6128 - loss: 1.0871\n",
      "Epoch 5/5\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6230 - loss: 1.0671\n",
      "Model trained and saved .\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from data_handling import get_mnist_data\n",
    "\n",
    "def train_model():\n",
    "    \"\"\"Trains a CNN model on MNIST dataset with ~40% accuracy and saves it.\"\"\"\n",
    "\n",
    "    x_train, y_train, x_test, y_test = get_mnist_data()\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(20, activation='relu'),  # Fewer neurons\n",
    "        tf.keras.layers.Dropout(0.65),  # Higher dropout\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.6),  # Increased LR\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x_train, y_train, epochs=5, batch_size=512, verbose=1)  # Reduced training\n",
    "\n",
    "    model.save('40_percent_accuracy_model.keras')\n",
    "    print(\"Model trained and saved .\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.2976 - loss: 1.9073 - val_accuracy: 0.8573 - val_loss: 0.5008\n",
      "Epoch 2/4\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.7730 - loss: 0.6892 - val_accuracy: 0.9004 - val_loss: 0.3375\n",
      "Epoch 3/4\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.8230 - loss: 0.5403 - val_accuracy: 0.9238 - val_loss: 0.2542\n",
      "Epoch 4/4\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.8523 - loss: 0.4567 - val_accuracy: 0.9423 - val_loss: 0.2030\n",
      "Model trained and saved.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from data_handling import get_mnist_data\n",
    "\n",
    "def train_model():\n",
    "    \"\"\"Trains a CNN model on MNIST dataset with 80-90% accuracy and saves it.\"\"\"\n",
    "\n",
    "    x_train, y_train, x_test, y_test = get_mnist_data()\n",
    "\n",
    "    # Normalize the data\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0  \n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28, 28, 1)),  \n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),  \n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),  # Moderate neurons\n",
    "        tf.keras.layers.Dropout(0.35),  # Balanced dropout to prevent overfitting\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.002),  # Slightly faster training\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x_train, y_train, epochs=4, batch_size=128, verbose=1, validation_data=(x_test, y_test))  \n",
    "\n",
    "    model.save('mnist_2.keras')\n",
    "    print(\"Model trained and saved.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
